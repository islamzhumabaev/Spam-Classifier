## Загрузка и предобработка данных

### Источник данных
Датасет взят с Kaggle: [SMS Spam Collection Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset). Он содержит SMS-сообщения, размеченные как "spam" или "ham" (не спам).

### Шаги обработки:

1. **Загрузка данных**
   Данные загружаются с указанием кодировки `latin1`, что необходимо для корректной работы с символами, содержащимися в тексте.

2. **Очистка таблицы**
   Удаляются ненужные колонки `Unnamed: 2`, `Unnamed: 3`, `Unnamed: 4`.

3. **Переименование столбцов**
   - `v1` переименован в `label` (целевой признак).
   - `v2` переименован в `text` (текст SMS-сообщения).

4. **Кодирование меток**
   С помощью `LabelEncoder` значения `ham` и `spam` преобразуются в числовые метки:
   - `0` — не спам (ham)
   - `1` — спам

5. **Обработка дубликатов**
   Проверка на пропущенные значения и дубли. Все дубликаты удалены.

6. **Балансировка классов**
   Распределение целевого признака (`label`):
   - Класс `0`: 4516 сообщений
   - Класс `1`: 653 сообщения
   Наблюдается значительный дисбаланс классов, что будет учитываться при обучении моделей.

## Анализ и визуализация данных

### Балансировка классов
Для оценки дисбаланса между спамом и не-спамом была построена круговая диаграмма на основе меток `label`. Распределение показало:
- 87.37% сообщений — не спам
- 12.63% сообщений — спам

Это подтверждает сильный дисбаланс классов, что важно учитывать при построении моделей классификации.

---

## Генерация новых признаков

Для дальнейшего анализа и построения модели были сгенерированы количественные признаки на основе текста сообщений:

1. **`characters_count`** — общее количество символов в сообщении.
2. **`words_count`** — количество слов.
3. **`sentences_count`** — количество предложений. Определяется по разделению текста по символам `.`, `?`, `!`.

После добавления новых признаков был выполнен обзор статистик с помощью `.describe()`, что позволило оценить распределение длины сообщений и плотность текста.

---

## Корреляционный анализ

Построена корреляционная матрица между числовыми признаками:
- Сильная корреляция между `characters_count`, `words_count` и `sentences_count` указывает на взаимосвязанность этих признаков.
- `characters_count` показывает умеренную положительную корреляцию с целевым признаком `label`, что может быть полезно для классификации.

Визуализация представлена с помощью тепловой карты (`seaborn.heatmap`) с включёнными коэффициентами корреляции.

## Предобработка текста

Для подготовки текста к векторизации и обучению моделей была реализована функция `preprocess_text`, включающая следующие этапы:

1. **Приведение к нижнему регистру**
2. **Удаление неалфавитных символов**
3. **Удаление стоп-слов и пунктуации**
4. **Лемматизация** — приведение слов к начальной форме с использованием `WordNetLemmatizer`.

Каждое сообщение очищается и сохраняется в новой колонке `preprocessed_text`.

---

## Визуализация ключевых слов (WordCloud)

Для анализа наиболее часто встречающихся слов в сообщениях были построены облака слов (`WordCloud`) отдельно для спам- и не-спам-сообщений:

- **Облако слов для спама** показало высокую частоту слов: `free`, `call`, `txt`, `mobile`, `claim`, `win`, `reply`.
- **Облако слов для не-спама** продемонстрировало повседневные разговорные выражения: `good`, `got`, `come`, `ok`, `know`, `love`.

Это помогает визуально выделить различия между двумя классами и определить потенциально значимые токены для моделей классификации.

---

## Векторизация текста

Для преобразования текстов в числовые представления используются два подхода:

- **`CountVectorizer`** — базовая мешочная модель слов (bag-of-words).
- **`TfidfVectorizer`** с ограничением `max_features=3000` — учитывает частоту термина и его значимость в корпусе сообщений.

Обе модели будут применяться при построении классификаторов для оценки влияния способа векторизации на итоговую метрику.

## Обучение моделей и сравнение алгоритмов классификации

После векторизации текста с использованием TF-IDF признаки были поданы на вход различным моделям машинного обучения. Цель — классификация SMS-сообщений на спам и не-спам.

### Разделение выборки
Данные разделены на обучающую и тестовую выборки в соотношении 80/20 с использованием `train_test_split`.

### Используемые модели

Были обучены и протестированы следующие классификаторы:

- Support Vector Machine (`SVM`)
- K-Nearest Neighbors (`KNN`)
- Naive Bayes (`MultinomialNB`)
- Decision Tree (`DT`)
- Logistic Regression (`LR`)
- Random Forest (`RF`)
- AdaBoost (`AdaBoostClassifier`)
- Gradient Boosting (`GBDT`)
- XGBoost (`XGBClassifier`)

Каждая модель обучалась на одних и тех же данных, после чего вычислялись следующие метрики:
- **Accuracy** — общая точность модели
- **Precision** — точность предсказания спама
- **Recall** — полнота (насколько хорошо модель выявляет весь спам)
- **F1-score** — гармоническое среднее точности и полноты

### Результаты

Примеры метрик на тестовой выборке:

| Model | Accuracy | Precision | Recall | F1-score |
|-------|----------|-----------|--------|----------|
| SVM   | 0.969    | 0.927     | 0.833  | 0.878    |
| KNN   | 0.903    | 1.000     | 0.275  | 0.432    |
| NB    | 0.966    | 0.990     | 0.754  | 0.856    |
| DT    | 0.937    | 0.848     | 0.645  | 0.733    |
| LR    | 0.950    | 0.922     | 0.681  | 0.783    |
| ...   | ...      | ...       | ...    | ...      |

Модели SVM и Naive Bayes показали лучшие результаты по F1-метрике, демонстрируя сбалансированную точность и полноту при обнаружении спама.

### Выводы

- Простые модели (Naive Bayes, SVM) работают эффективно на задаче классификации коротких текстов.
- Важно учитывать не только точность, но и полноту — особенно в задачах обнаружения спама, где пропущенные случаи критичны.
- Классы в датасете несбалансированы, поэтому использование F1-метрики оправдано для оценки общей эффективности.
